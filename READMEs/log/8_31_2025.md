# TLDR

High level steps of what I think is needed...

1. Auth to GCP
1. Create a GCP Pub/Sub Topic
1. Build a simple Cloud Function (this is actually what this code repo is)
1. Test the simple Cloud Function locally
1. Enable `cloudfunctions.googleapis.com` on the project
1. Set up a Google Cloud Function to act as the subscriber to the topic
1. Publish to the Topic from the FastAPI

## How to auth to GCP

- gcloud auth login <!-- trigger auth flow from CLI to GCP -->
- gcloud config list <!-- Review gcloud CLI settings -->

## Create a GCP Pub/Sub Topic

- https://cloud.google.com/pubsub/docs/create-topic
- Using the `gcloud pubsub topics create TOPIC_ID`
- ie: `gcloud pubsub topics create kb-ingest-topic`
- Verify topic was created: `https://console.cloud.google.com/cloudpubsub/topic/list`

## Enable Cloud Functions & Eventarc in the GCP Project

- `gcloud services enable cloudfunctions.googleapis.com`
- `gcloud services enable eventarc.googleapis.com`

## Deploy the Cloud Function

```sh
gcloud functions deploy processPubSubMessage \
--runtime=nodejs22 \
--trigger-topic=kb-ingest-topic \
--region=us-east1 \
--memory=1GB \
--timeout=540s \
--source ./build \
--entry-point=processPubSubMessage \
--gen2
```

## Test the Cloud function

- `gcloud pubsub topics publish kb-ingest-topic --message='{"action":"process","key":"value"}' --attribute=test=true`
- `gcloud functions logs tail processPubSubMessage --region=us-east1`
- `gcloud functions logs read processPubSubMessage --region=us-east1 --limit=50`

## Scaffold out the API endpoint (ie: `kalygo3-ai-api`)

Peep the `src/routers/similaritySearch/upload.py` path of the `kalygo3-ai-api` repo

## Provision a Service Account to give to the `kalygo3-ai-api`

The Service Account will give the API permissions to upload data to GCS (Google Cloud Storage)

### Create bucket in GCS console with default settings

```sh
gcloud storage buckets create gs://kalygo-kb-ingest-storage \
  --location=us-east1 \
  --uniform-bucket-level-access \
  --public-access-prevention
  --project $PROJECT_ID
```

### Grant the relevant service account permissions to access Google Cloud Storage:

```sh - 1. Create service account
gcloud iam service-accounts create kalygo3-kb-ingest-sa \
    --display-name="Kalygo KB In Service Account" \
    --description="Enables Kalygo v3 AI API to ingest knowledge at scale - USES GCS and Pub/Sub most notably" \
    --project=$PROJECT_ID
```

```sh - 2. Create and download key
gcloud iam service-accounts keys create kalygo3-kb-ingest-sa-key.json \
    --iam-account=kalygo3-kb-ingest-sa@kalygo-436411.iam.gserviceaccount.com \
    --project=$PROJECT_ID
```

```sh - 3. Grant bucket read/write access
gsutil iam ch serviceAccount:kalygo3-kb-ingest-sa@${PROJECT_ID}.iam.gserviceaccount.com:objectAdmin gs://kalygo-kb-ingest-storage
# Grant GCS storage.admin role
gcloud storage buckets add-iam-policy-binding gs://kalygo-kb-ingest-storage \
--member="serviceAccount:kalygo3-kb-ingest-sa@kalygo-436411.iam.gserviceaccount.com" \
--role="roles/storage.admin"
# Grant Pub/Sub Publisher role
gcloud projects add-iam-policy-binding kalygo-436411 \
    --member="serviceAccount:kalygo3-kb-ingest-sa@kalygo-436411.iam.gserviceaccount.com" \
    --role="roles/pubsub.publisher"
```

```sh - 4. Verify
gsutil iam get gs://kalygo-kb-ingest-storage
```